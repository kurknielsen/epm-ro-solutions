CREATE OR REPLACE PACKAGE BODY CDI_INTERVAL_USAGE AS

TYPE t_LOOKUP_ERROR IS TABLE OF PLS_INTEGER INDEX BY VARCHAR2(128);
TYPE t_LOSS_FACTOR_CACHE IS TABLE OF NUMBER(8,6) INDEX BY VARCHAR2(32);

c_PACKAGE_NAME                 CONSTANT VARCHAR2(32) := 'CDI_INTERVAL_USAGE';
c_IMPORT_INTERVAL_USAGE        CONSTANT VARCHAR2(64) := 'CDI: Import Interval (MV90) Usage';
c_REPOST_INTERVAL_USAGE        CONSTANT VARCHAR2(64) := 'CDI: Repost Interval (MV90) Usage';
c_LOAD_INTERVAL_USAGE_FILE     CONSTANT VARCHAR2(64) := 'CDI: Load Interval (MV90) Usage File';
c_ALLOCATE_COMMUNITY_SOLAR     CONSTANT VARCHAR2(64) := 'CDI: Allocate Community Solar';
c_SYSTEM_SETTING_MODULE        CONSTANT VARCHAR2(32) := 'Client Data Interface';
c_SYSTEM_SETTING_KEY1          CONSTANT VARCHAR2(32) := 'Data Import';
c_SYSTEM_SETTING_KEY2          CONSTANT VARCHAR2(32) := 'Interval Usage';
c_SETTING_LOG_LEVEL            CONSTANT VARCHAR2(32) := 'Log Level';
c_SETTING_LOSS_FACTOR_NAME     CONSTANT VARCHAR2(32) := 'Distribution Loss Factor';
c_DEFAULT_LOSS_FACTOR          CONSTANT VARCHAR2(32) := 'SEC';
c_DATE_FORMAT                  CONSTANT VARCHAR2(16) := 'MM/DD/YYYY';
c_USAGE_DAY_FORMAT             CONSTANT VARCHAR2(16) := 'DD-MON-YYYY';
c_DATE_TIME_FORMAT             CONSTANT VARCHAR2(32) := 'MM/DD/YYYY HH24:MI:SS';
c_STATUS_SUCCESS               CONSTANT VARCHAR2(16) := 'Success';
c_STATUS_ERROR                 CONSTANT VARCHAR2(16) := 'Error';
c_DATA_INTERVAL_TYPE           CONSTANT NUMBER(1)    := 1;
c_DAY_TYPE                     CONSTANT CHAR(1)      := '1';
c_RECORD_ACTION_PROCESS        CONSTANT CHAR(1)      := '1';
c_RECORD_ACTION_IGNORE         CONSTANT CHAR(1)      := '0';
c_CRLF                         CONSTANT CHAR(2) := CHR(13) || CHR(10);
c_LOOP_COUNTER_LIMIT           CONSTANT PLS_INTEGER  := 1000000;

l_MV90_RAW_DATA_ROW_ID         PLS_INTEGER := 1;
l_LOSS_FACTOR_CACHE            t_LOSS_FACTOR_CACHE;
l_WARN_ENTITY_LOOKUP_ANOMALY   BOOLEAN := FALSE;

PROCEDURE GATHER_TABLE_STATS(p_TABLE_NAME IN VARCHAR2) IS
BEGIN
   DBMS_STATS.GATHER_TABLE_STATS(OWNNAME => USER, TABNAME => p_TABLE_NAME, ESTIMATE_PERCENT => DBMS_STATS.AUTO_SAMPLE_SIZE, BLOCK_SAMPLE => TRUE, DEGREE => NULL, CASCADE => TRUE);
END GATHER_TABLE_STATS;

PROCEDURE INITIALIZE_INTERFACE AS
v_LOG_LEVEL VARCHAR2(32);
BEGIN 
   v_LOG_LEVEL := NVL(UPPER(GET_DICTIONARY_VALUE(c_SETTING_LOG_LEVEL, GA.GLOBAL_MODEL, c_SYSTEM_SETTING_MODULE, c_SYSTEM_SETTING_KEY1, c_SYSTEM_SETTING_KEY2)),'INFO');
   IF v_LOG_LEVEL NOT IN ('INFO','DEBUG') THEN
      LOGS.LOG_WARN('Setting ' || c_SETTING_LOG_LEVEL || ': ' || v_LOG_LEVEL || ' Is Invalid.');
   ELSE
      LOGS.LOG_INFO('Setting ' || c_SETTING_LOG_LEVEL || ': ' || TO_CHAR(v_LOG_LEVEL));
   END IF;
   IF v_LOG_LEVEL = 'DEBUG' THEN
      LOGS.SET_CURRENT_LOG_LEVEL(LOGS.c_LEVEL_DEBUG);
      LOGS.SET_PERSISTING_TRACE(TRUE);
   END IF;
END INITIALIZE_INTERFACE;

PROCEDURE LOAD_INTERVAL_USAGE_FILE
   (
   p_IMPORT_FILE      IN CLOB,
   p_IMPORT_FILE_PATH IN VARCHAR2,
   p_STATUS          OUT NUMBER,
   p_MESSAGE         OUT VARCHAR2
   ) AS
v_BEGIN_POS  PLS_INTEGER := 1;
v_END_POS    PLS_INTEGER := 1;
v_LENGTH     PLS_INTEGER;
v_COUNTER    PLS_INTEGER;
v_LINE_COUNT PLS_INTEGER := 0;
v_OFFSET     PLS_INTEGER;
v_MARK_TIME  PLS_INTEGER := DBMS_UTILITY.GET_TIME;
v_DELIMITER  VARCHAR2(5);
v_LINE       VARCHAR2(32767);
v_MESSAGE    VARCHAR2(1000);
v_CONTENT    CLOB;
BEGIN
-- Start The Process Log --
   LOGS.START_PROCESS(c_LOAD_INTERVAL_USAGE_FILE);
   p_MESSAGE := '';
   p_STATUS := 0;
    EXECUTE IMMEDIATE 'TRUNCATE TABLE TEMP_MV90_RAW_DATA';
   v_DELIMITER := UTL_TCP.CRLF;
   v_CONTENT := RTRIM(p_IMPORT_FILE, UTL_TCP.CRLF);
   v_OFFSET := CASE WHEN v_DELIMITER = UTL_TCP.CRLF THEN 2 ELSE 1 END;
   v_LENGTH := LENGTH(v_CONTENT);
   v_COUNTER := 0;
   LOOP
      v_END_POS := INSTR(v_CONTENT, v_DELIMITER, v_BEGIN_POS);
      IF v_END_POS = 0 THEN
         v_LINE := LTRIM(RTRIM(SUBSTR(v_CONTENT, v_BEGIN_POS)));
         v_END_POS := v_LENGTH;
      ELSE
         v_LINE := LTRIM(RTRIM(SUBSTR(v_CONTENT, v_BEGIN_POS, v_END_POS - v_BEGIN_POS)));
      END IF;
      v_LINE_COUNT := v_LINE_COUNT + 1;
      INSERT INTO TEMP_MV90_RAW_DATA VALUES('MV90', v_LINE, v_LINE_COUNT);
      v_BEGIN_POS := v_END_POS + v_OFFSET;
      v_COUNTER := v_COUNTER + 1;
      IF v_COUNTER > c_LOOP_COUNTER_LIMIT THEN
         ERRS.LOG_AND_RAISE('Processing Loop Counter Exceeds Upper Limit Of ' || TO_CHAR(c_LOOP_COUNTER_LIMIT));
      END IF;
      IF MOD(v_COUNTER, 1000) = 0 THEN
         COMMIT;
      END IF;
      EXIT WHEN v_BEGIN_POS > v_LENGTH;
   END LOOP;
   IF SUBSTR(v_CONTENT, v_LENGTH) = v_DELIMITER THEN
     v_LINE_COUNT := v_LINE_COUNT + 1;
   END IF;
   p_MESSAGE := 'Number Of Records Posted To The TEMP_MV90_RAW_DATA Table: ' || TO_CHAR(v_LINE_COUNT);
   LOGS.LOG_INFO(p_MESSAGE);
   COMMIT;
-- Stop The Process Log --
   LOGS.LOG_INFO(c_LOAD_INTERVAL_USAGE_FILE || ' Complete. Elapsed Seconds: ' || TO_CHAR(ROUND((DBMS_UTILITY.GET_TIME-v_MARK_TIME)/100)));
   LOGS.STOP_PROCESS(p_MESSAGE, p_STATUS);
-- Import The Content From The File Loading Process -- 
   IF v_LINE_COUNT > 0 THEN
      IMPORT_INTERVAL_USAGE(p_STATUS, v_MESSAGE);
      p_MESSAGE := p_MESSAGE || c_CRLF || v_MESSAGE;
   END IF;
EXCEPTION
   WHEN OTHERS THEN
      p_MESSAGE := SQLERRM;
      p_STATUS := SQLCODE;
      LOGS.LOG_ERROR('Value_Error - Counter: ' || TO_CHAR(v_COUNTER) || ', Token: ' || v_LINE || ', Begin: ' || TO_CHAR(v_BEGIN_POS) || ', End: ' || TO_CHAR(v_END_POS) || ', Length: ' || TO_CHAR(v_LENGTH));
      ERRS.ABORT_PROCESS;
END LOAD_INTERVAL_USAGE_FILE;

FUNCTION ROUND_START_MINUTE(p_START_MINUTE IN NUMBER) RETURN NUMBER AS
BEGIN
   RETURN CASE WHEN p_START_MINUTE <= 15 THEN 15 WHEN p_START_MINUTE <= 30 THEN 30 WHEN p_START_MINUTE <= 45 THEN 45 WHEN p_START_MINUTE <= 60 THEN 60 ELSE 0 END;
END;

FUNCTION IS_NUMBER(p_STRING IN VARCHAR2) RETURN BOOLEAN AS
v_NUMBER NUMBER;
BEGIN
   v_NUMBER := TO_NUMBER(TRIM(p_STRING));
   RETURN TRUE;
EXCEPTION
   WHEN VALUE_ERROR THEN
      RETURN FALSE;
END IS_NUMBER;

FUNCTION IS_RIGHT_ROW (p_STRING IN VARCHAR2) RETURN BOOLEAN AS
BEGIN
   IF p_STRING LIKE '0001%' AND (l_MV90_RAW_DATA_ROW_ID = 1 OR l_MV90_RAW_DATA_ROW_ID  > 999) THEN
      RETURN TRUE;
   ELSIF p_STRING LIKE '0002%' AND l_MV90_RAW_DATA_ROW_ID = 2 THEN
      RETURN TRUE;
   ELSIF p_STRING LIKE '0003%' AND l_MV90_RAW_DATA_ROW_ID = 3 THEN
      RETURN TRUE;
   ELSIF p_STRING LIKE '0004%' AND l_MV90_RAW_DATA_ROW_ID = 4 THEN
      RETURN TRUE;
   ELSIF p_STRING NOT LIKE '0%' AND l_MV90_RAW_DATA_ROW_ID > 999 THEN
      RETURN TRUE;
   ELSE
      RETURN FALSE;
   END IF;
END IS_RIGHT_ROW;

FUNCTION TO_CSV(p_CDI_MV90_DATA IN OUT CDI_MV90_DATA%ROWTYPE) RETURN VARCHAR2 AS
BEGIN
   RETURN p_CDI_MV90_DATA.CHANNEL || ',' || p_CDI_MV90_DATA.IS_ALTERNATE_FORMAT || ',' || TO_CHAR(p_CDI_MV90_DATA.PULSE_MULTIPLIER) || ',' || TO_CHAR(p_CDI_MV90_DATA.PULSE_OFFSET) || ',' || TO_CHAR(p_CDI_MV90_DATA.ALTERNATE_PULSE_MULTIPLIER) || ',' || TO_CHAR(p_CDI_MV90_DATA.PREMISE_NUMBER) || ',' || TO_CHAR(p_CDI_MV90_DATA.KW) || ',' || p_CDI_MV90_DATA.STATUS_CODE || ',' || TO_CHAR(LOGS.CURRENT_PROCESS_ID);
END TO_CSV;
 
PROCEDURE PARSE_PULSE_LINE
   (
   p_CURRENT_LINE  IN VARCHAR2,
   p_CUT_TIME      IN OUT DATE,
   p_MULTIPLIER    IN NUMBER,
   p_CDI_MV90_DATA IN OUT CDI_MV90_DATA%ROWTYPE
   ) AS
v_INDEX    PLS_INTEGER := 5;
v_INTERVAL VARCHAR2(6);
v_SYSDATE  DATE := SYSDATE;
v_MESSAGE  VARCHAR2(512);
v_NUMBER   NUMBER;
v_OFFSET   NUMBER;
BEGIN
-- Pulse Data Is Located In Positions 5-76 Of The Record. It Contains 12 Intervals Of Pulse Data; The First 5 Characters Are The Pulse; The Sixth Character Is The Status; Valid Data Has Status Of Space (Null)--
-- A Status Code of "9" Indicates A Reverse Flow. The Pulse Will Be Set To Zero (0). --
   WHILE v_INDEX < 77 LOOP
      p_CDI_MV90_DATA.STATUS_CODE := TRIM(SUBSTR(p_CURRENT_LINE, v_INDEX + 5, 1));
      IF p_CDI_MV90_DATA.STATUS_CODE IS NULL OR p_CDI_MV90_DATA.STATUS_CODE <> '9' THEN
         v_INTERVAL := TRIM(SUBSTR(p_CURRENT_LINE,v_INDEX, 5));
         IF v_INTERVAL IS NOT NULL AND LENGTH(v_INTERVAL) = 5 THEN
            v_NUMBER := TO_NUMBER((SUBSTR(p_CURRENT_LINE, v_INDEX, 5)),'99999.9999');
            v_OFFSET := TO_NUMBER(p_CDI_MV90_DATA.PULSE_OFFSET/10000,'99999.99999');
            p_CDI_MV90_DATA.KW := TO_NUMBER(TO_CHAR((v_NUMBER * p_MULTIPLIER + v_OFFSET),'999999.9999'),'999999.99999');
         ELSE
            v_MESSAGE := 'Invalid Pulse Data';
            l_MV90_RAW_DATA_ROW_ID := 1;
            EXIT;
         END IF;
         BEGIN
            INSERT /* APPEND*/ INTO CDI_MV90_DATA(CHANNEL, CUT_INTERVAL, IS_ALTERNATE_FORMAT, PULSE_MULTIPLIER, PULSE_OFFSET, ALTERNATE_PULSE_MULTIPLIER, PREMISE_NUMBER, KW, STATUS_CODE, PROCESS_ID, CREATE_DATE_TIME)
            VALUES(p_CDI_MV90_DATA.CHANNEL, p_CUT_TIME, p_CDI_MV90_DATA.IS_ALTERNATE_FORMAT, p_CDI_MV90_DATA.PULSE_MULTIPLIER, p_CDI_MV90_DATA.PULSE_OFFSET, p_CDI_MV90_DATA.ALTERNATE_PULSE_MULTIPLIER, p_CDI_MV90_DATA.PREMISE_NUMBER, p_CDI_MV90_DATA.KW, p_CDI_MV90_DATA.STATUS_CODE, LOGS.CURRENT_PROCESS_ID, v_SYSDATE);
         EXCEPTION
            WHEN DUP_VAL_ON_INDEX THEN
               v_MESSAGE := 'Duplicate Index Values';
               LOGS.LOG_WARN(v_MESSAGE);
               UPDATE CDI_MV90_DATA SET
                  IS_ALTERNATE_FORMAT        = p_CDI_MV90_DATA.IS_ALTERNATE_FORMAT,
                  PULSE_MULTIPLIER           = p_CDI_MV90_DATA.PULSE_MULTIPLIER,
                  PULSE_OFFSET               = p_CDI_MV90_DATA.PULSE_OFFSET,
                  ALTERNATE_PULSE_MULTIPLIER = p_CDI_MV90_DATA.ALTERNATE_PULSE_MULTIPLIER,
                  PREMISE_NUMBER             = p_CDI_MV90_DATA.PREMISE_NUMBER,
                  KW                         = p_CDI_MV90_DATA.KW,
                  STATUS_CODE                = p_CDI_MV90_DATA.STATUS_CODE,
                  PROCESS_ID                 = LOGS.CURRENT_PROCESS_ID,
                  CREATE_DATE_TIME           = v_SYSDATE
               WHERE CHANNEL = p_CDI_MV90_DATA.CHANNEL
                   AND CUT_INTERVAL = p_CUT_TIME;
            WHEN OTHERS THEN
               ERRS.LOG_AND_RAISE('Pulse Record: ' || TO_CSV(p_CDI_MV90_DATA));
         END;
      END IF;
      p_CUT_TIME := p_CUT_TIME + 15/1440;
      v_INDEX := v_INDEX + 6;
   END LOOP;
   IF v_MESSAGE IS NULL THEN
      l_MV90_RAW_DATA_ROW_ID := l_MV90_RAW_DATA_ROW_ID + 1;
   ELSE
      LOGS.LOG_ERROR('Error Detected In Pulse Line: ' || v_MESSAGE);
      l_MV90_RAW_DATA_ROW_ID := 1;
   END IF;
END PARSE_PULSE_LINE;

PROCEDURE PARSE_FIRST_LINE(p_CURRENT_LINE IN VARCHAR2, p_CDI_MV90_DATA IN OUT CDI_MV90_DATA%ROWTYPE, p_START_DATE OUT DATE) AS
v_MESSAGE         VARCHAR2(512);
v_START_DATE_TIME VARCHAR2(10);
v_START_HOUR      NUMBER(2);
v_START_MINUTE    NUMBER(2);
v_EXTRA_ID        VARCHAR2(2);
v_RECORD_ACTION   CHAR(1) := c_RECORD_ACTION_PROCESS;
BEGIN
-- Check If The Study Id Is Valid (Nothing In Position 13-14)--
   v_EXTRA_ID := TRIM(SUBSTR(UPPER(p_CURRENT_LINE),13,2));
   IF v_EXTRA_ID IS NOT NULL THEN
      v_RECORD_ACTION := c_RECORD_ACTION_IGNORE;
      v_MESSAGE := 'Invalid Channel (Study_Id: ' || v_EXTRA_ID || '), ';
   ELSE
      p_CDI_MV90_DATA.CHANNEL := TRIM(SUBSTR(UPPER(p_CURRENT_LINE),5,12));
      IF SUBSTR(p_CURRENT_LINE,49,1) <> c_RECORD_ACTION_PROCESS THEN
         v_RECORD_ACTION := c_RECORD_ACTION_IGNORE;
         v_MESSAGE := 'Invalid Unit Of Measure Flag (' || SUBSTR(p_CURRENT_LINE,49,1) || '), ';
      END IF;
      v_START_DATE_TIME := SUBSTR(p_CURRENT_LINE,26,10);
      IF IS_NUMBER(v_START_DATE_TIME) THEN
         p_START_DATE := TO_DATE(SUBSTR(v_START_DATE_TIME,1,2) || '/' || SUBSTR(v_START_DATE_TIME,3,2) || '/' || SUBSTR(v_START_DATE_TIME,5,2),'MM/DD/YY');
         v_START_HOUR := TO_NUMBER(SUBSTR(v_START_DATE_TIME,7,2));
         v_START_MINUTE:= ROUND_START_MINUTE(SUBSTR(v_START_DATE_TIME,9,2));
         IF v_START_MINUTE = 60 THEN
            v_START_HOUR   := v_START_HOUR + 1;
            v_START_MINUTE := 0;
         END IF;
         IF v_START_HOUR <= 24 THEN
            p_START_DATE := p_START_DATE + v_START_HOUR/24 + v_START_MINUTE/1440;
            p_START_DATE := TO_CUT(p_START_DATE, 'EDT');
         ELSE
            v_RECORD_ACTION := c_RECORD_ACTION_IGNORE;
            v_MESSAGE   := v_MESSAGE ||'Invalid Start Hour, ';
         END IF;
      ELSE
         v_RECORD_ACTION := c_RECORD_ACTION_IGNORE;
         v_MESSAGE := v_MESSAGE || 'Invalid Start Date, ';
      END IF;
   END IF;
   IF v_RECORD_ACTION = c_RECORD_ACTION_IGNORE THEN
      LOGS.LOG_ERROR('LINE (0001): ' || RTRIM(v_MESSAGE, ', ') || ', Record: ' || p_CURRENT_LINE);
      l_MV90_RAW_DATA_ROW_ID := 1;
   ELSE
      p_CDI_MV90_DATA.IS_ALTERNATE_FORMAT := SUBSTR(p_CURRENT_LINE,50,1);
      l_MV90_RAW_DATA_ROW_ID := 2;
   END IF;
EXCEPTION
   WHEN OTHERS THEN
      ERRS.LOG_AND_RAISE;
END PARSE_FIRST_LINE;

PROCEDURE PARSE_SECOND_LINE(p_CURRENT_LINE IN VARCHAR2, p_CDI_MV90_DATA IN OUT CDI_MV90_DATA%ROWTYPE) AS
v_RECORD_ACTION CHAR(1) := c_RECORD_ACTION_PROCESS;
v_MESSAGE VARCHAR2(512);
BEGIN
-- Pulse Multiplier --
   IF IS_NUMBER(SUBSTR(p_CURRENT_LINE,34,15)) THEN
      p_CDI_MV90_DATA.PULSE_MULTIPLIER := TO_NUMBER(TRIM(SUBSTR(p_CURRENT_LINE,34,15)));
  ELSE
     v_RECORD_ACTION := c_RECORD_ACTION_IGNORE;
     v_MESSAGE   := 'Invalid Pulse Multiplier';
   END IF;
-- Pulse_Offset --
   IF IS_NUMBER(SUBSTR(p_CURRENT_LINE,65,16)) THEN
      p_CDI_MV90_DATA.PULSE_OFFSET := TO_NUMBER(TRIM(SUBSTR(UPPER(p_CURRENT_LINE),65,16)));
   ELSE
      v_RECORD_ACTION := c_RECORD_ACTION_IGNORE;
      v_MESSAGE   := 'Invalid Pulse Offset';
   END IF;
  IF v_RECORD_ACTION = c_RECORD_ACTION_IGNORE THEN
      LOGS.LOG_ERROR('Line (0002): ' || v_MESSAGE);
      l_MV90_RAW_DATA_ROW_ID := 1;
  ELSE
     l_MV90_RAW_DATA_ROW_ID := 3;
  END IF;
END PARSE_SECOND_LINE;

PROCEDURE PARSE_THIRD_LINE(p_CURRENT_LINE  IN VARCHAR2, p_CDI_MV90_DATA IN OUT CDI_MV90_DATA%ROWTYPE, p_MULTIPLIER OUT NUMBER) AS
BEGIN
   IF IS_NUMBER(SUBSTR(p_CURRENT_LINE,45,15))  THEN
      p_CDI_MV90_DATA.ALTERNATE_PULSE_MULTIPLIER := TO_NUMBER(TRIM(SUBSTR(p_CURRENT_LINE,45,15)));
      p_MULTIPLIER:= TO_NUMBER(((p_CDI_MV90_DATA.PULSE_MULTIPLIER * (1 - TO_NUMBER(p_CDI_MV90_DATA.IS_ALTERNATE_FORMAT)) + (p_CDI_MV90_DATA.ALTERNATE_PULSE_MULTIPLIER) * TO_NUMBER(p_CDI_MV90_DATA.IS_ALTERNATE_FORMAT)/10000000000)/100000));
      l_MV90_RAW_DATA_ROW_ID := 4;
   ELSE
      LOGS.LOG_ERROR('Line (0003): Invalid Alternate_Pulse_Multiplier');
      l_MV90_RAW_DATA_ROW_ID := 1;
   END IF;
END PARSE_THIRD_LINE;

PROCEDURE POPULATE_STAGING_TABLE(p_HAVE_CONTENT IN OUT BOOLEAN, p_MESSAGE IN OUT VARCHAR2) IS
-- Parse The Raw MV90 Data To 15 Minute Intervals And Post It To The CDI_USAGE_MV90 Table --
-- General Rules:
--   1) Header Rows Start With 0001, 0002, 0003, 0004
--   2) Process A Study Id Only If Header Row 1 Has Unit Of Measure Of Data = 1
--   3) Valid Study Ids Have Length 7 Or 8 Characters
--   4) Valid Intervals Have Interval Status Of Blank " " In The Input File
CURSOR c_SELECT IS SELECT FILENAME, ROW_DATA, SEQ_VAL, FILENAME || ',' || ROW_DATA || ',' || TO_CHAR(SEQ_VAL) "CSV_RECORD" FROM TEMP_MV90_RAW_DATA ORDER BY SEQ_VAL;
v_START_DATE_TIME DATE;
v_MULTIPLIER      NUMBER(18,8);
v_COMMIT_COUNTER  PLS_INTEGER := 0;
v_RECORD_COUNT    PLS_INTEGER := 0;
v_INPUT_COUNT     PLS_INTEGER;
v_MARK_TIME       PLS_INTEGER := DBMS_UTILITY.GET_TIME;
v_STEP_NAME       VARCHAR2(32);
v_CDI_MV90_DATA   CDI_MV90_DATA%ROWTYPE;
BEGIN
-- Select Content From Table TEMP_MV90_RAW_DATA And Loop Through It Process Every Row, Break Into Intervals And Insert Into The CDI_MV90_DATA Table --
   EXECUTE IMMEDIATE('TRUNCATE TABLE CDI_MV90_DATA');
   l_MV90_RAW_DATA_ROW_ID := 1;
   FOR v_SELECT IN c_SELECT LOOP
      LOGS.LOG_DEBUG('MV90 Record: ' || v_SELECT.CSV_RECORD);
      BEGIN
         SAVEPOINT BEGIN_BLOCK;
-- Header Comprises 4 Lines --
         IF IS_RIGHT_ROW(v_SELECT.ROW_DATA)  THEN
-- Header Line 1 --
            IF v_SELECT.ROW_DATA LIKE '0001%' THEN
               v_STEP_NAME := 'HEADER_LINE_1';
               IF l_MV90_RAW_DATA_ROW_ID > 1000 THEN
                  COMMIT;
                  v_COMMIT_COUNTER := 0;
               END IF;
               v_MULTIPLIER := 0;
               PARSE_FIRST_LINE(v_SELECT.ROW_DATA, v_CDI_MV90_DATA, v_START_DATE_TIME);
-- Header Line 2 --
            ELSIF l_MV90_RAW_DATA_ROW_ID = 2 THEN
               v_STEP_NAME := 'HEADER_LINE_2';
               PARSE_SECOND_LINE(v_SELECT.ROW_DATA, v_CDI_MV90_DATA);
-- Header Line 3 --
            ELSIF l_MV90_RAW_DATA_ROW_ID = 3 THEN
               v_STEP_NAME := 'HEADER_LINE_3';
               PARSE_THIRD_LINE(v_SELECT.ROW_DATA, v_CDI_MV90_DATA, v_MULTIPLIER);
-- Header Line 4 --
            ELSIF l_MV90_RAW_DATA_ROW_ID = 4 THEN
               v_STEP_NAME := 'HEADER_LINE_4';
               v_CDI_MV90_DATA.PREMISE_NUMBER := TO_NUMBER(TRIM(SUBSTR(v_SELECT.ROW_DATA,5,10)));
               l_MV90_RAW_DATA_ROW_ID := 1000;
--Pulse Block --
            ELSIF l_MV90_RAW_DATA_ROW_ID > 999 THEN
               v_STEP_NAME := 'PULSE_LINE';
               PARSE_PULSE_LINE(v_SELECT.ROW_DATA, v_START_DATE_TIME, v_MULTIPLIER, v_CDI_MV90_DATA);
               v_COMMIT_COUNTER := v_COMMIT_COUNTER + 1;
               v_RECORD_COUNT   := v_RECORD_COUNT + 1;
            END IF;
         END IF;
      EXCEPTION
         WHEN OTHERS THEN
            ERRS.LOG_AND_CONTINUE('Error Parsing Data Block', p_STEP_NAME => v_STEP_NAME);
            LOGS.LOG_ERROR('Error Parsing Data Block, Row Number: ' || TO_CHAR(v_SELECT.SEQ_VAL) || ', Row Data: ' || v_SELECT.ROW_DATA);
            l_MV90_RAW_DATA_ROW_ID := 1;
            v_RECORD_COUNT := v_RECORD_COUNT - v_COMMIT_COUNTER;
            IF v_COMMIT_COUNTER > 0 THEN
               ROLLBACK TO BEGIN_BLOCK;
            END IF;
      END;
   END LOOP;
   COMMIT;
   SELECT COUNT(*) INTO v_INPUT_COUNT FROM TEMP_MV90_RAW_DATA;
   LOGS.LOG_INFO('Number Of Records Posted To CDI_MV90_DATA Staging Table: ' || TO_CHAR(v_RECORD_COUNT));
   LOGS.LOG_INFO('Elapsed Seconds: ' || TO_CHAR(ROUND((DBMS_UTILITY.GET_TIME-v_MARK_TIME)/100)));
   p_HAVE_CONTENT := TRUE;
   IF v_INPUT_COUNT > 0 AND v_RECORD_COUNT = 0 THEN
      p_MESSAGE := TO_CHAR(v_INPUT_COUNT) || ' Input Records Were Processed But No Content Was Parsed.';
      LOGS.LOG_ERROR(p_MESSAGE);
      p_HAVE_CONTENT := FALSE;
   END IF;
END POPULATE_STAGING_TABLE;

PROCEDURE ARCHIVE_MV90_DATA AS
v_COUNT PLS_INTEGER;
v_MARK_TIME PLS_INTEGER := DBMS_UTILITY.GET_TIME;
BEGIN
   COMMIT;
   MERGE INTO CDI_MV90_ARCHIVE T
      USING (SELECT CHANNEL, CUT_INTERVAL, IS_ALTERNATE_FORMAT, PULSE_MULTIPLIER, PULSE_OFFSET, ALTERNATE_PULSE_MULTIPLIER, PREMISE_NUMBER, KW, STATUS_CODE, PROCESS_ID, CREATE_DATE_TIME FROM CDI_MV90_DATA) S
      ON (T.CHANNEL = S.CHANNEL AND T.CUT_INTERVAL = S.CUT_INTERVAL)
      WHEN MATCHED THEN
         UPDATE SET T.IS_ALTERNATE_FORMAT = S.IS_ALTERNATE_FORMAT, T.PULSE_MULTIPLIER = S.PULSE_MULTIPLIER, T.PULSE_OFFSET = S.PULSE_OFFSET, T.ALTERNATE_PULSE_MULTIPLIER = S.ALTERNATE_PULSE_MULTIPLIER, T.PREMISE_NUMBER = S.PREMISE_NUMBER, T.KW = S.KW, T.STATUS_CODE = S.STATUS_CODE, T.PROCESS_ID = S.PROCESS_ID, T.LAST_UPDATE_DATE_TIME = SYSDATE 
      WHEN NOT MATCHED THEN
         INSERT(CHANNEL, CUT_INTERVAL, IS_ALTERNATE_FORMAT, PULSE_MULTIPLIER, PULSE_OFFSET, ALTERNATE_PULSE_MULTIPLIER, PREMISE_NUMBER, KW, STATUS_CODE, PROCESS_ID, CREATE_DATE_TIME, LAST_UPDATE_DATE_TIME)
         VALUES (S.CHANNEL, S.CUT_INTERVAL, S.IS_ALTERNATE_FORMAT,S.PULSE_MULTIPLIER, S.PULSE_OFFSET, S.ALTERNATE_PULSE_MULTIPLIER, S.PREMISE_NUMBER, S.KW, S.STATUS_CODE, S.PROCESS_ID, S.CREATE_DATE_TIME, SYSDATE);
   v_COUNT := SQL%ROWCOUNT;       
   LOGS.LOG_INFO('Number Of Records Posted To CDI_MV90_ARCHIVE Table: ' || TO_CHAR(v_COUNT));
   LOGS.LOG_INFO('Elapsed Seconds: ' || TO_CHAR(ROUND((DBMS_UTILITY.GET_TIME-v_MARK_TIME)/100)));
   COMMIT;
END ARCHIVE_MV90_DATA;

PROCEDURE GET_HOURLY_KW_DATA(p_BEGIN_DATE IN DATE, p_END_DATE IN DATE, p_PROCESS_ID IN NUMBER) AS
v_BEGIN_DATE DATE;
v_END_DATE   DATE;
v_COUNT      PLS_INTEGER;
v_MARK_TIME  PLS_INTEGER := DBMS_UTILITY.GET_TIME;
BEGIN
   EXECUTE IMMEDIATE 'TRUNCATE TABLE CDI_MV90_CHANNEL_DATE';
   EXECUTE IMMEDIATE 'TRUNCATE TABLE CDI_MV90_DATA_CACHE';
   IF p_PROCESS_ID IS NULL THEN
      INSERT /* APPEND */ INTO CDI_MV90_DATA_CACHE(CHANNEL, STUDY_ID, KW_DATE, KW_VAL, LOCAL_DAY_TRUNC_DATE)
      WITH MV90_CONTENT AS
         (SELECT CHANNEL, SUBSTR(CHANNEL,1,4) "STUDY_ID",  TRUNC(CUT_INTERVAL+59/1440,'HH') "KW_DATE", SUM(KW) "KW_VAL", COUNT(TRUNC(CUT_INTERVAL+59/1440,'HH'))
         FROM CDI_MV90_ARCHIVE_CACHE
         WHERE  CHANNEL NOT LIKE 'C%'
            AND CHANNEL NOT LIKE '1650%'
            AND CHANNEL NOT LIKE '1649%'
            AND CHANNEL NOT IN (SELECT STUDY_ID FROM STUDYID_EXCEPTION_LOOKUP)
            AND CUT_INTERVAL BETWEEN p_BEGIN_DATE AND p_END_DATE
         GROUP BY CHANNEL, TRUNC(CUT_INTERVAL+59/1440,'HH') HAVING COUNT(TRUNC(CUT_INTERVAL+59/1440,'HH')) = 4)
      SELECT X.STUDY_ID, X.STUDY_ID, X.KW_DATE, SUM(X.KW_VAL), SDT.LOCAL_DAY_TRUNC_DATE
      FROM MV90_CONTENT X
         JOIN SYSTEM_DATE_TIME SDT ON SDT.TIME_ZONE = GA.LOCAL_TIME_ZONE AND SDT.DATA_INTERVAL_TYPE = c_DATA_INTERVAL_TYPE AND SDT.DAY_TYPE = c_DAY_TYPE AND SDT.STANDARD_DATE = X.KW_DATE
      GROUP BY X.STUDY_ID, X.KW_DATE, SDT.LOCAL_DAY_TRUNC_DATE;
      v_COUNT := SQL%ROWCOUNT;
   ELSE
      INSERT INTO CDI_MV90_CHANNEL_DATE(CHANNEL, LOCAL_DAY_TRUNC_DATE)
      SELECT DISTINCT CHANNEL, LOCAL_DAY_TRUNC_DATE
      FROM CDI_MV90_DATA X
         JOIN SYSTEM_DATE_TIME SDT ON SDT.TIME_ZONE = GA.LOCAL_TIME_ZONE AND SDT.DATA_INTERVAL_TYPE = c_DATA_INTERVAL_TYPE AND SDT.DAY_TYPE = c_DAY_TYPE AND SDT.STANDARD_DATE = TRUNC(X.CUT_INTERVAL + 59/1440,'HH')
      WHERE  CHANNEL NOT LIKE 'C%'
         AND CHANNEL NOT LIKE '1650%'
         AND CHANNEL NOT LIKE '1649%'
         AND CHANNEL NOT IN (SELECT STUDY_ID FROM STUDYID_EXCEPTION_LOOKUP);
      INSERT INTO CDI_MV90_DATA_CACHE(CHANNEL, STUDY_ID, KW_DATE, KW_VAL, LOCAL_DAY_TRUNC_DATE)
      WITH MV90_CHANNEL_DATE AS
         (SELECT MCD.CHANNEL, SDT.STANDARD_DATE, MCD.LOCAL_DAY_TRUNC_DATE
         FROM CDI_MV90_CHANNEL_DATE MCD
            JOIN SYSTEM_DATE_TIME SDT ON SDT.TIME_ZONE = GA.LOCAL_TIME_ZONE AND SDT.DATA_INTERVAL_TYPE = c_DATA_INTERVAL_TYPE AND SDT.DAY_TYPE = c_DAY_TYPE AND SDT.LOCAL_DAY_TRUNC_DATE = MCD.LOCAL_DAY_TRUNC_DATE)
      SELECT SUBSTR(A.CHANNEL,1,4) "CHANNEL", SUBSTR(A.CHANNEL,1,4) "STUDY_ID", B.STANDARD_DATE "KW_DATE", SUM(A.KW) "KW_VAL", B.LOCAL_DAY_TRUNC_DATE
      FROM CDI_MV90_ARCHIVE_CACHE A
         JOIN MV90_CHANNEL_DATE B ON B.CHANNEL = A.CHANNEL AND A.CUT_INTERVAL > B.STANDARD_DATE-1/24 AND A.CUT_INTERVAL <= B.STANDARD_DATE
      GROUP BY SUBSTR(A.CHANNEL,1,4), B.STANDARD_DATE, B.LOCAL_DAY_TRUNC_DATE;
      v_COUNT := SQL%ROWCOUNT;
   END IF;
   COMMIT;
   LOGS.LOG_INFO('Number Of Records Posted To CDI_MV90_DATA_CACHE Table: ' || TO_CHAR(v_COUNT) || ', Process Id: ' || NVL(TO_CHAR(p_PROCESS_ID),'Null'));
   LOGS.LOG_INFO('Elapsed Seconds: ' || TO_CHAR(ROUND((DBMS_UTILITY.GET_TIME-v_MARK_TIME)/100)));
END GET_HOURLY_KW_DATA;

PROCEDURE GET_HOURLY_1650_DATA(p_BEGIN_DATE IN DATE, p_END_DATE IN DATE, p_PROCESS_ID IN NUMBER) AS
v_COUNT     PLS_INTEGER;
v_MARK_TIME PLS_INTEGER := DBMS_UTILITY.GET_TIME;
BEGIN
   IF p_PROCESS_ID IS NULL THEN
      INSERT /* APPEND */ INTO CDI_MV90_DATA_CACHE(CHANNEL, STUDY_ID, KW_DATE, KW_VAL, LOCAL_DAY_TRUNC_DATE)
      SELECT '1650' "CHANNEL", '1650' "STUDY_ID", X.KW_DATE, X.KW_VAL, SDT.LOCAL_DAY_TRUNC_DATE
      FROM
         (SELECT KW_DATE, SUM(KW_VAL) "KW_VAL"
         FROM
            (SELECT KW_DATE, KW_VAL
            FROM
               (SELECT TRUNC(R.KW_DATE+59/1440,'HH') "KW_DATE", SUM(R.KW_VAL) "KW_VAL", COUNT(TRUNC(R.KW_DATE+59/1440,'HH'))
               FROM
                  (SELECT A.CUT_INTERVAL "KW_DATE", SUM(A.KW*B.WEIGHT) "KW_VAL"
                  FROM CDI_MV90_ARCHIVE_CACHE A
                     JOIN STUDYID_EXCEPTION_LOOKUP B ON B.STUDY_ID = A.CHANNEL
                  WHERE B.SEGMENT = '1650'
                     AND A.CUT_INTERVAL BETWEEN p_BEGIN_DATE AND p_END_DATE
                  GROUP BY A.CUT_INTERVAL) R
               GROUP BY TRUNC(KW_DATE+59/1440,'HH') HAVING COUNT(TRUNC(KW_DATE+59/1440,'HH')) = 4)
            UNION
            SELECT KW_DATE, KW_VAL
            FROM
               (SELECT CHANNEL, SUBSTR(CHANNEL,1,4) "STUDY_ID", TRUNC(CUT_INTERVAL+59/1440,'HH') "KW_DATE", SUM(KW) "KW_VAL", COUNT(TRUNC(CUT_INTERVAL+59/1440,'HH'))
               FROM CDI_MV90_ARCHIVE_CACHE
               WHERE CHANNEL LIKE '1650%'
                  AND CUT_INTERVAL BETWEEN p_BEGIN_DATE AND p_END_DATE
               GROUP BY CHANNEL, TRUNC(CUT_INTERVAL+59/1440,'HH') HAVING COUNT(TRUNC(CUT_INTERVAL+59/1440,'HH')) = 4))
         GROUP BY KW_DATE) X
         JOIN SYSTEM_DATE_TIME SDT ON SDT.TIME_ZONE = GA.LOCAL_TIME_ZONE AND SDT.DATA_INTERVAL_TYPE = c_DATA_INTERVAL_TYPE AND SDT.DAY_TYPE = c_DAY_TYPE AND SDT.STANDARD_DATE = X.KW_DATE;
      v_COUNT := SQL%ROWCOUNT;
   ELSE
      INSERT /* APPEND */  INTO CDI_MV90_DATA_CACHE(CHANNEL, STUDY_ID, KW_DATE, KW_VAL, LOCAL_DAY_TRUNC_DATE)
      SELECT '1650' "CHANNEL", '1650' "STUDY_ID", X.KW_DATE, X.KW_VAL, SDT.LOCAL_DAY_TRUNC_DATE
      FROM
         (SELECT KW_DATE, SUM(KW_VAL) "KW_VAL"
         FROM
            (SELECT KW_DATE, KW_VAL
            FROM
               (SELECT TRUNC(R.KW_DATE+59/1440,'HH') "KW_DATE", SUM(R.KW_VAL) "KW_VAL", COUNT(TRUNC(R.KW_DATE+59/1440,'HH'))
               FROM
                  (SELECT (A.CUT_INTERVAL) "KW_DATE", SUM(A.KW*B.WEIGHT) "KW_VAL"
                  FROM CDI_MV90_ARCHIVE_CACHE A
                     JOIN STUDYID_EXCEPTION_LOOKUP B ON B.SEGMENT = '1650' AND B.STUDY_ID = A.CHANNEL
                  WHERE A.PROCESS_ID = p_PROCESS_ID
                  GROUP BY A.CUT_INTERVAL) R
               GROUP BY TRUNC(KW_DATE+59/1440,'HH') HAVING COUNT(TRUNC(KW_DATE+59/1440,'HH')) = 4)
            UNION ALL
            SELECT KW_DATE, KW_VAL
            FROM
               (SELECT CHANNEL, SUBSTR(CHANNEL,1,4) "STUDY_ID", TRUNC(CUT_INTERVAL+59/1440,'HH') "KW_DATE", SUM(KW) "KW_VAL", COUNT(TRUNC(CUT_INTERVAL+59/1440,'HH'))
               FROM CDI_MV90_ARCHIVE_CACHE
               WHERE PROCESS_ID = p_PROCESS_ID
                  AND CHANNEL LIKE '1650%'
               GROUP BY CHANNEL, TRUNC(CUT_INTERVAL+59/1440,'HH') HAVING COUNT(TRUNC(CUT_INTERVAL+59/1440,'HH')) = 4))
         GROUP BY KW_DATE) X
         JOIN SYSTEM_DATE_TIME SDT ON SDT.TIME_ZONE = GA.LOCAL_TIME_ZONE AND SDT.DATA_INTERVAL_TYPE = c_DATA_INTERVAL_TYPE AND SDT.DAY_TYPE = c_DAY_TYPE AND SDT.STANDARD_DATE = X.KW_DATE;
      v_COUNT := SQL%ROWCOUNT;
   END IF;
   COMMIT;
   LOGS.LOG_INFO('Number Of Records Posted To CDI_MV90_DATA_CACHE Table: ' || TO_CHAR(v_COUNT) || ', Process Id: ' || NVL(TO_CHAR(p_PROCESS_ID),'Null'));
   LOGS.LOG_INFO('Elapsed Seconds: ' || TO_CHAR(ROUND((DBMS_UTILITY.GET_TIME-v_MARK_TIME)/100)));
END GET_HOURLY_1650_DATA;

PROCEDURE GET_HOURLY_1649_DATA(p_BEGIN_DATE IN DATE, p_END_DATE IN DATE, p_PROCESS_ID IN NUMBER) AS
v_COUNT     PLS_INTEGER;
v_MARK_TIME PLS_INTEGER := DBMS_UTILITY.GET_TIME;
BEGIN
   IF p_PROCESS_ID IS NULL THEN
      INSERT /* APPEND */  INTO CDI_MV90_DATA_CACHE(CHANNEL, STUDY_ID, KW_DATE, KW_VAL, LOCAL_DAY_TRUNC_DATE)
      SELECT '1649' "CHANNEL" , '1649' "STUDY_ID", X.KW_DATE, X.KW_VAL, SDT.LOCAL_DAY_TRUNC_DATE
      FROM
         (SELECT KW_DATE, SUM(KW_VAL) "KW_VAL"
         FROM
            (SELECT KW_DATE, KW_VAL
            FROM
               (SELECT TRUNC(R.KW_DATE+59/1440,'HH') "KW_DATE", SUM(R.KW_VAL) "KW_VAL", COUNT(TRUNC(R.KW_DATE+59/1440,'HH'))
               FROM
                  (SELECT A.CUT_INTERVAL "KW_DATE", SUM(A.KW*B.WEIGHT) "KW_VAL"
                  FROM CDI_MV90_ARCHIVE_CACHE A
                     JOIN STUDYID_EXCEPTION_LOOKUP B ON B.SEGMENT = '1649' AND B.STUDY_ID = A.CHANNEL
                  WHERE A.CUT_INTERVAL BETWEEN p_BEGIN_DATE AND p_END_DATE
                  GROUP BY A.CUT_INTERVAL) R
               GROUP BY TRUNC(KW_DATE+59/1440,'HH') HAVING COUNT(TRUNC(KW_DATE+59/1440,'HH')) = 4)
            UNION ALL
            SELECT KW_DATE, KW_VAL
            FROM
               (SELECT CHANNEL, SUBSTR(CHANNEL,1,4) "STUDY_ID", TRUNC(CUT_INTERVAL+59/1440,'HH') "KW_DATE", SUM(KW) "KW_VAL", COUNT(TRUNC(CUT_INTERVAL+59/1440,'HH'))
               FROM CDI_MV90_ARCHIVE_CACHE
               WHERE CHANNEL LIKE '1649%'
                  AND CUT_INTERVAL BETWEEN p_BEGIN_DATE AND p_END_DATE
               GROUP BY CHANNEL, TRUNC(CUT_INTERVAL+59/1440,'HH') HAVING COUNT(TRUNC(CUT_INTERVAL+59/1440,'HH')) = 4))
         GROUP BY KW_DATE) X
            JOIN SYSTEM_DATE_TIME SDT ON SDT.TIME_ZONE = GA.LOCAL_TIME_ZONE AND SDT.DATA_INTERVAL_TYPE = c_DATA_INTERVAL_TYPE AND SDT.DAY_TYPE = c_DAY_TYPE AND SDT.STANDARD_DATE = X.KW_DATE;
      v_COUNT := SQL%ROWCOUNT;
   ELSE
      INSERT /* APPEND */ INTO CDI_MV90_DATA_CACHE(CHANNEL, STUDY_ID, KW_DATE, KW_VAL, LOCAL_DAY_TRUNC_DATE)
      SELECT  '1649' "CHANNEL" , '1649' "STUDY_ID", X.KW_DATE, X.KW_VAL, SDT.LOCAL_DAY_TRUNC_DATE
      FROM
         (SELECT KW_DATE, SUM(KW_VAL) "KW_VAL"
         FROM
            (SELECT KW_DATE, KW_VAL
            FROM
               (SELECT TRUNC(R.KW_DATE+59/1440,'HH') "KW_DATE", SUM(R.KW_VAL) "KW_VAL", COUNT(TRUNC(R.KW_DATE+59/1440,'HH'))
               FROM
                  (SELECT A.CUT_INTERVAL "KW_DATE", SUM(A.KW*B.WEIGHT) "KW_VAL"
                  FROM CDI_MV90_ARCHIVE_CACHE A
                     JOIN STUDYID_EXCEPTION_LOOKUP B ON B.SEGMENT = '1649' AND B.STUDY_ID = A.CHANNEL
                  WHERE A.PROCESS_ID = p_PROCESS_ID
                  GROUP BY A.CUT_INTERVAL) R
               GROUP BY TRUNC(KW_DATE+59/1440,'HH') HAVING COUNT(TRUNC(KW_DATE+59/1440,'HH')) = 4)
            UNION ALL
            SELECT KW_DATE, KW_VAL
            FROM
               (SELECT CHANNEL, SUBSTR(CHANNEL,1,4) "STUDY_ID", TRUNC(CUT_INTERVAL+59/1440,'HH') "KW_DATE", SUM(KW) "KW_VAL", COUNT(TRUNC(CUT_INTERVAL+59/1440,'HH'))
               FROM CDI_MV90_ARCHIVE_CACHE
               WHERE PROCESS_ID = p_PROCESS_ID
                  AND CHANNEL LIKE '1649%'
               GROUP BY CHANNEL,TRUNC(CUT_INTERVAL+59/1440,'HH') HAVING COUNT(TRUNC(CUT_INTERVAL+59/1440,'HH')) = 4))
         GROUP BY KW_DATE) X
            JOIN SYSTEM_DATE_TIME SDT ON SDT.TIME_ZONE = GA.LOCAL_TIME_ZONE AND SDT.DATA_INTERVAL_TYPE = c_DATA_INTERVAL_TYPE AND SDT.DAY_TYPE = c_DAY_TYPE AND SDT.STANDARD_DATE = X.KW_DATE;
      v_COUNT := SQL%ROWCOUNT;
   END IF;
   COMMIT;
   LOGS.LOG_INFO('Number Of Records Posted To CDI_MV90_DATA_CACHE Table: ' || TO_CHAR(v_COUNT) || ', Process Id: ' || NVL(TO_CHAR(p_PROCESS_ID),'Null'));
   LOGS.LOG_INFO('Elapsed Seconds: ' || TO_CHAR(ROUND((DBMS_UTILITY.GET_TIME-v_MARK_TIME)/100)));
END GET_HOURLY_1649_DATA;

PROCEDURE GET_MV90_COLLECTION(p_BEGIN_DATE IN DATE, p_END_DATE IN DATE, p_PROCESS_ID IN NUMBER) AS
v_COUNT     PLS_INTEGER;
v_MARK_TIME PLS_INTEGER := DBMS_UTILITY.GET_TIME;
v_BEGIN_DATE DATE;
v_END_DATE   DATE;
BEGIN
   EXECUTE IMMEDIATE 'TRUNCATE TABLE CDI_MV90_ARCHIVE_CACHE';
   UT.CUT_DATE_RANGE(p_BEGIN_DATE, p_END_DATE, GA.LOCAL_TIME_ZONE, v_BEGIN_DATE, v_END_DATE);
   LOGS.LOG_INFO('Begin Cut Date: ' || TO_CHAR(v_BEGIN_DATE, c_DATE_TIME_FORMAT) || ', End Cut Date: ' || TO_CHAR(v_END_DATE, c_DATE_TIME_FORMAT));
   INSERT /*APPEND*/ INTO CDI_MV90_ARCHIVE_CACHE SELECT * FROM CDI_MV90_ARCHIVE WHERE CUT_INTERVAL BETWEEN v_BEGIN_DATE AND v_END_DATE;
   LOGS.LOG_INFO('MV90 Archive Cache Count: ' || TO_CHAR(SQL%ROWCOUNT));
   COMMIT;  
   IF LOGS.CURRENT_LOG_LEVEL > LOGS.c_LEVEL_DEBUG THEN
      LOGS.SET_CURRENT_LOG_LEVEL(LOGS.c_LEVEL_DEBUG);
   END IF;
   GATHER_TABLE_STATS('CDI_MV90_ARCHIVE_CACHE');
   GET_HOURLY_KW_DATA(v_BEGIN_DATE, v_END_DATE, p_PROCESS_ID);
   GET_HOURLY_1650_DATA(v_BEGIN_DATE, v_END_DATE, p_PROCESS_ID);
   GET_HOURLY_1649_DATA(v_BEGIN_DATE, v_END_DATE, p_PROCESS_ID);
   SELECT COUNT(*) INTO v_COUNT FROM CDI_MV90_DATA_CACHE;
   IF v_COUNT = 0 THEN
      LOGS.LOG_WARN('MV90 Input Data Collection Is Empty');
   ELSE
      LOGS.LOG_INFO('MV90 Input Data Collection Count: ' || TO_CHAR(v_COUNT));
   END IF;
   LOGS.LOG_INFO('Elapsed Seconds: ' || TO_CHAR(ROUND((DBMS_UTILITY.GET_TIME-v_MARK_TIME)/100)));
END GET_MV90_COLLECTION;

PROCEDURE POST_MV90_IMPORT_ACCOUNTS AS
v_COUNT PLS_INTEGER;
BEGIN
   SELECT NVL(COUNT(*),0) INTO v_COUNT FROM CDI_MV90_IMPORT_ACCOUNT;
   IF v_COUNT = 0 THEN
      INSERT INTO CDI_MV90_IMPORT_ACCOUNT(ACCOUNT_ID, ACCOUNT_NAME, ACCOUNT_EXTERNAL_IDENTIFIER)
      SELECT ACCOUNT_ID, ACCOUNT_NAME, ACCOUNT_EXTERNAL_IDENTIFIER
      FROM ACCOUNT
      WHERE ACCOUNT_MODEL_OPTION = 'Account'
         AND ACCOUNT_METER_TYPE = 'Interval';
      v_COUNT := SQL%ROWCOUNT;
      COMMIT;
      LOGS.LOG_INFO('Number Of Records Posted To The CDI_MV90_IMPORT_ACCOUNT Table: ' || TO_CHAR(v_COUNT));
   END IF;
END POST_MV90_IMPORT_ACCOUNTS;

PROCEDURE POST_MV90_IMPORT_CANDIDATES AS
v_EARLIEST_DATE DATE;
BEGIN
   SELECT MIN(LOCAL_DAY_TRUNC_DATE) - 1 INTO v_EARLIEST_DATE FROM CDI_MV90_DATA_CACHE;
   LOGS.LOG_INFO('Earliest Date: ' || TO_CHAR(v_EARLIEST_DATE, c_DATE_FORMAT));

   EXECUTE IMMEDIATE 'TRUNCATE TABLE CDI_PBS_CUSTOMER_LOOKUP';
   INSERT INTO CDI_PBS_CUSTOMER_LOOKUP(BILL_ACCOUNT, "SERVICE_POINT", STUDY_ID, EFFECTIVE_DATE, TERMINATION_DATE)
   SELECT BILL_ACCOUNT, "SERVICE_POINT", STUDY_ID, EFFECTIVE_DATE, TERMINATION_DATE
   FROM PBS_CUSTOMER_LOOKUP_VIEW
   WHERE TERMINATION_DATE >= v_EARLIEST_DATE;
   LOGS.LOG_INFO('Number Of Records Posted To The PBS_CUSTOMER_LOOKUP_TEMP Table: ' || TO_CHAR(SQL%ROWCOUNT));
   COMMIT;

   POST_MV90_IMPORT_ACCOUNTS;
   
   EXECUTE IMMEDIATE 'TRUNCATE TABLE CDI_BGE_RTO_STUDY';
   INSERT INTO CDI_BGE_RTO_STUDY(STUDY_ID, BILL_ACCOUNT, AGGR_IDENTIFIER, EFFECTIVE_DATE, TERMINATION_DATE, ACCOUNT_ID, ACCOUNT_NAME, ACCOUNT_EXTERNAL_IDENTIFIER)
   SELECT BGE.STUDY_ID, BGE.BILL_ACCOUNT, BGE.AGGR_IDENTIFIER, MIN(BGE.EFFECTIVE_DATE), MAX(BGE.TERMINATION_DATE), NVL(ACT.ACCOUNT_ID, 0), NVL(ACT.ACCOUNT_NAME, 'NA'), NVL(ACT.ACCOUNT_EXTERNAL_IDENTIFIER, 'NA')
   FROM BGE_MASTER_ACCOUNT         BGE
      JOIN CDI_PBS_CUSTOMER_LOOKUP PBS ON PBS.BILL_ACCOUNT = BGE.BILL_ACCOUNT
      JOIN CDI_MV90_IMPORT_ACCOUNT  ACT ON ACT.ACCOUNT_NAME = BGE.AGGR_IDENTIFIER
   WHERE BGE.TERMINATION_DATE >= v_EARLIEST_DATE
   GROUP BY BGE.STUDY_ID, BGE.BILL_ACCOUNT, BGE.AGGR_IDENTIFIER, NVL(ACT.ACCOUNT_ID, 0), NVL(ACT.ACCOUNT_NAME, 'NA'), NVL(ACT.ACCOUNT_EXTERNAL_IDENTIFIER, 'NA');
   LOGS.LOG_INFO('Number Of Records Posted To The BGE_RTO_STUDY_TEMP Table: ' || TO_CHAR(SQL%ROWCOUNT));
   COMMIT;

END POST_MV90_IMPORT_CANDIDATES;

PROCEDURE POST_SERVICE_IDENTITY AS
CURSOR c_SELECT IS SELECT ACCOUNT_EXTERNAL_IDENT, STAGING_MESSAGE FROM CDI_SERVICE_IDENTITY WHERE STAGING_STATUS = c_STATUS_ERROR ORDER BY IDENTITY_ID;
v_COUNT PLS_INTEGER;
BEGIN
   EXECUTE IMMEDIATE 'TRUNCATE TABLE CDI_SERVICE_IDENTITY';
   INSERT INTO CDI_SERVICE_IDENTITY(SERVICE_DATE, ACCOUNT_EXTERNAL_IDENT)
   SELECT A.LOCAL_DAY_TRUNC_DATE "SERVICE_DATE", ACCOUNT_EXTERNAL_IDENTIFIER "ACCOUNT_EXTERNAL_IDENT"
   FROM CDI_MV90_DATA_CACHE A
      JOIN CDI_BGE_RTO_STUDY B ON B.STUDY_ID = A.STUDY_ID
   GROUP BY LOCAL_DAY_TRUNC_DATE, ACCOUNT_EXTERNAL_IDENTIFIER;
   LOGS.LOG_DEBUG('Number Of Records Posted To The CDI_SERVICE_IDENTITY Table: ' || TO_CHAR(SQL%ROWCOUNT));
   COMMIT;
   CDI_SERVICE.ENSURE_SERVICE_IDENTITY;
   SELECT COUNT(*) INTO v_COUNT FROM CDI_SERVICE_IDENTITY WHERE STAGING_STATUS = c_STATUS_ERROR;
   IF v_COUNT > 0 AND l_WARN_ENTITY_LOOKUP_ANOMALY THEN
      LOGS.LOG_WARN('Entity Lookup Anomaly. Listing Follows.');
      FOR v_SELECT IN c_SELECT LOOP
         LOGS.LOG_WARN(v_SELECT.ACCOUNT_EXTERNAL_IDENT || ' - ' || v_SELECT.STAGING_MESSAGE);
      END LOOP;
   END IF;
END POST_SERVICE_IDENTITY;

PROCEDURE DELETE_SERVICE(p_SERVICE_DATE IN DATE, p_DELETE_ALL IN BOOLEAN) AS
v_BEGIN_DATE DATE;
v_END_DATE DATE;
v_MARK_TIME PLS_INTEGER := DBMS_UTILITY.GET_TIME;
BEGIN
   UT.CUT_DATE_RANGE(p_SERVICE_DATE, GA.LOCAL_TIME_ZONE, v_BEGIN_DATE, v_END_DATE);
   LOGS.LOG_DEBUG('Begin Cut Date: ' || TO_CHAR(v_BEGIN_DATE, c_DATE_TIME_FORMAT) || ', End Cut Date: ' || TO_CHAR(v_END_DATE, c_DATE_TIME_FORMAT));
   IF p_DELETE_ALL THEN
      DELETE SERVICE_LOAD
      WHERE SERVICE_ID IN (SELECT SERVICE_ID FROM SERVICE_STATE WHERE SERVICE_DATE = p_SERVICE_DATE AND SERVICE_CODE = CONSTANTS.CODE_ACTUAL AND METER_TYPE = 'I' AND IS_AGGREGATE_ACCOUNT = 0) 
         AND SERVICE_CODE = CONSTANTS.CODE_ACTUAL
         AND LOAD_DATE BETWEEN v_BEGIN_DATE AND v_END_DATE;
      LOGS.LOG_DEBUG('Delete Service Load Record Count: ' || TO_CHAR(SQL%ROWCOUNT));
      DELETE SERVICE_STATE
      WHERE SERVICE_DATE = p_SERVICE_DATE
         AND SERVICE_CODE = CONSTANTS.CODE_ACTUAL
         AND METER_TYPE = 'I'
         AND IS_AGGREGATE_ACCOUNT = 0;
      LOGS.LOG_DEBUG('Delete Service State Record Count: ' || TO_CHAR(SQL%ROWCOUNT));
   ELSE
      DELETE SERVICE_LOAD X
      WHERE EXISTS (SELECT NULL FROM CDI_SERVICE_IDENTITY WHERE SERVICE_ID = X.SERVICE_ID) 
         AND SERVICE_CODE = CONSTANTS.CODE_ACTUAL
         AND LOAD_DATE BETWEEN v_BEGIN_DATE AND v_END_DATE;
      LOGS.LOG_DEBUG('Delete Service Load Record Count: ' || TO_CHAR(SQL%ROWCOUNT));
      DELETE SERVICE_STATE X
      WHERE EXISTS (SELECT NULL FROM CDI_SERVICE_IDENTITY WHERE SERVICE_ID = X.SERVICE_ID) 
         AND SERVICE_DATE = p_SERVICE_DATE
         AND SERVICE_CODE = CONSTANTS.CODE_ACTUAL
         AND METER_TYPE = 'I'
         AND IS_AGGREGATE_ACCOUNT = 0;
      LOGS.LOG_DEBUG('Delete Service State Record Count: ' || TO_CHAR(SQL%ROWCOUNT));
   END IF;
   LOGS.LOG_DEBUG('Delete Service Complete. Total Elapsed Seconds: ' || TO_CHAR(ROUND((DBMS_UTILITY.GET_TIME-v_MARK_TIME)/100)));
END DELETE_SERVICE;

PROCEDURE POST_SERVICE_STATE(p_SERVICE_DATE IN DATE, p_COUNT IN OUT PLS_INTEGER) AS
v_COUNT PLS_INTEGER;
v_MARK_TIME PLS_INTEGER := DBMS_UTILITY.GET_TIME;
BEGIN
   MERGE INTO SERVICE_STATE T
   USING
      (SELECT SERVICE_ID, CONSTANTS.CODE_ACTUAL "SERVICE_CODE", p_SERVICE_DATE "SERVICE_DATE", CURRENT_DATE AS BASIS_AS_OF_DATE, 'I' "METER_TYPE", 0 "IS_EXTERNAL_FORECAST", 0 "IS_AGGREGATE_ACCOUNT", 1 "SERVICE_ACCOUNTS", 0 "IS_UFE_PARTICIPANT"
      FROM CDI_SERVICE_IDENTITY
      WHERE SERVICE_DATE = p_SERVICE_DATE
         AND SERVICE_ID IS NOT NULL) S
   ON (T.SERVICE_ID = S.SERVICE_ID AND T.SERVICE_CODE = S.SERVICE_CODE AND T.SERVICE_DATE = S.SERVICE_DATE)
   WHEN NOT MATCHED THEN
      INSERT(SERVICE_ID, SERVICE_CODE, SERVICE_DATE, BASIS_AS_OF_DATE, METER_TYPE, IS_EXTERNAL_FORECAST, IS_AGGREGATE_ACCOUNT, SERVICE_ACCOUNTS, IS_UFE_PARTICIPANT)
      VALUES(S.SERVICE_ID, S.SERVICE_CODE, S.SERVICE_DATE, S.BASIS_AS_OF_DATE, S.METER_TYPE, S.IS_EXTERNAL_FORECAST, S.IS_AGGREGATE_ACCOUNT, S.SERVICE_ACCOUNTS, S.IS_UFE_PARTICIPANT);
   v_COUNT := SQL%ROWCOUNT;
   LOGS.LOG_DEBUG('Post Service State Complete. Records Posted: ' || TO_CHAR(v_COUNT) ||', Total Elapsed Seconds: ' || TO_CHAR(ROUND((DBMS_UTILITY.GET_TIME-v_MARK_TIME)/100)));
   COMMIT;
   p_COUNT := p_COUNT + v_COUNT;
END POST_SERVICE_STATE;

PROCEDURE POST_SERVICE_LOAD(p_SERVICE_DATE IN DATE, p_COUNT IN OUT PLS_INTEGER) AS
v_BEGIN_DATE DATE;
v_END_DATE DATE;
v_COUNT PLS_INTEGER;
v_MARK_TIME PLS_INTEGER := DBMS_UTILITY.GET_TIME;
BEGIN
   UT.CUT_DATE_RANGE(p_SERVICE_DATE, GA.LOCAL_TIME_ZONE, v_BEGIN_DATE, v_END_DATE);
   LOGS.LOG_DEBUG('Begin Cut Date: ' || TO_CHAR(v_BEGIN_DATE, c_DATE_TIME_FORMAT) || ', End Cut Date: ' || TO_CHAR(v_END_DATE, c_DATE_TIME_FORMAT));
   CDI_SERVICE.SET_LOSS_FACTOR(p_SERVICE_DATE);
   INSERT INTO SERVICE_LOAD(SERVICE_ID, SERVICE_CODE, LOAD_DATE, LOAD_CODE, LOAD_VAL, DX_LOSS_VAL, TX_LOSS_VAL, UE_LOSS_VAL)
   SELECT SERVICE_ID, CONSTANTS.CODE_ACTUAL "SERVICE_CODE", LOAD_DATE, GA.STANDARD "LOAD_CODE", LOAD_VAL, LOAD_VAL * DX_EXPANSION_FACTOR "DX_LOSS_VAL", (LOAD_VAL + (LOAD_VAL * DX_EXPANSION_FACTOR)) * TX_EXPANSION_FACTOR "TX_LOSS_VAL", 0 "UE_LOSS_VAL"
   FROM
      (SELECT X.SERVICE_ID, DX_EXPANSION_FACTOR, TX_EXPANSION_FACTOR, TRUNC(M.CUT_INTERVAL+59/1440,'HH') "LOAD_DATE", SUM(KW) "LOAD_VAL"
      FROM CDI_SERVICE_IDENTITY X
         JOIN CDI_BGE_RTO_STUDY S ON S.ACCOUNT_ID = X.ACCOUNT_ID 
         JOIN CDI_MV90_ARCHIVE  M ON SUBSTR(M.CHANNEL,1,4) = S.STUDY_ID AND M.CUT_INTERVAL BETWEEN v_BEGIN_DATE AND v_END_DATE
      WHERE X.SERVICE_ID IS NOT NULL
         AND SERVICE_DATE = p_SERVICE_DATE
      GROUP BY X.SERVICE_ID, X.DX_EXPANSION_FACTOR, X.TX_EXPANSION_FACTOR, TRUNC(M.CUT_INTERVAL+59/1440,'HH'));
   v_COUNT := SQL%ROWCOUNT;
   LOGS.LOG_DEBUG('Post Service Load Complete. Records Posted: ' || TO_CHAR(v_COUNT) || '. Total Elapsed Seconds: ' || TO_CHAR(ROUND((DBMS_UTILITY.GET_TIME-v_MARK_TIME)/100)));
   COMMIT;
   p_COUNT := p_COUNT + v_COUNT;
END POST_SERVICE_LOAD;

PROCEDURE POST_MV90_HOURLY_DEMAND(p_SERVICE_DATE IN DATE, p_COUNT IN OUT PLS_INTEGER) AS
v_COUNT PLS_INTEGER;
v_MARK_TIME  PLS_INTEGER := DBMS_UTILITY.GET_TIME;
BEGIN
   DELETE CDI_MV90_HOURLY_DEMAND
   WHERE ACCOUNT_EXTERNAL_IDENTIFIER IN (SELECT DISTINCT ACCOUNT_EXTERNAL_IDENT FROM CDI_SERVICE_IDENTITY WHERE SERVICE_DATE = p_SERVICE_DATE AND SERVICE_ID IS NOT NULL)
      AND SERVICE_DATE = p_SERVICE_DATE;
   LOGS.LOG_DEBUG('Delete MV90 Hourly Demand Record Count: ' || TO_CHAR(SQL%ROWCOUNT));
   INSERT INTO CDI_MV90_HOURLY_DEMAND(ACCOUNT_EXTERNAL_IDENTIFIER, SERVICE_DATE, HR01, HR02, HR03, HR04, HR05, HR06, HR07, HR08, HR09, HR10, HR11, HR12, HR13, HR14, HR15, HR16, HR17, HR18, HR19, HR20, HR21, HR22, HR23, HR24, HR25, ENTRY_DATE)
   WITH CANDIDATES AS (SELECT DISTINCT ACCOUNT_EXTERNAL_IDENT, SERVICE_ID FROM CDI_SERVICE_IDENTITY WHERE SERVICE_DATE = p_SERVICE_DATE AND SERVICE_ID IS NOT NULL)
   SELECT C.ACCOUNT_EXTERNAL_IDENT, p_SERVICE_DATE, HR01, HR02, HR03, HR04, HR05, HR06, HR07, HR08, HR09, HR10, HR11, HR12, HR13, HR14, HR15, HR16, HR17, HR18, HR19, HR20, HR21, HR22, HR23, HR24, HR25, CURRENT_DATE
   FROM CANDIDATES C
      JOIN CDI_MV90_HOURLY_DEMAND$ D ON D.SERVICE_ID = C.SERVICE_ID AND D.SERVICE_DATE = p_SERVICE_DATE;
   v_COUNT := SQL%ROWCOUNT;
   LOGS.LOG_DEBUG('Post MV90 Hourly Demand Complete. Records Posted: ' || TO_CHAR(v_COUNT) || '. Total Elapsed Seconds: ' || TO_CHAR(ROUND((DBMS_UTILITY.GET_TIME-v_MARK_TIME)/100)));
   COMMIT;
   p_COUNT := p_COUNT + v_COUNT;
END POST_MV90_HOURLY_DEMAND;

PROCEDURE PROCESS_INTERVAL_USAGE
   (
   p_BEGIN_DATE IN DATE   DEFAULT NULL,
   p_END_DATE   IN DATE   DEFAULT NULL,
   p_PROCESS_ID IN NUMBER DEFAULT NULL
   ) AS
v_BEGIN_DATE   DATE := TRUNC(p_BEGIN_DATE);
v_END_DATE     DATE := TRUNC(p_END_DATE);
v_SERVICE_DATE DATE;
v_SS_COUNT  PLS_INTEGER := 0;
v_SL_COUNT  PLS_INTEGER := 0;
v_HD_COUNT  PLS_INTEGER := 0;
v_MARK_TIME PLS_INTEGER := DBMS_UTILITY.GET_TIME;
   FUNCTION FROM_CUT_TO_LOCAL_DAY(p_CUT_DATE IN DATE) RETURN DATE AS
   v_LOCAL_DAY DATE;
   BEGIN
      SELECT LOCAL_DAY_TRUNC_DATE INTO v_LOCAL_DAY FROM SYSTEM_DATE_TIME WHERE TIME_ZONE = GA.LOCAL_TIME_ZONE AND DATA_INTERVAL_TYPE = 1 AND DAY_TYPE = '1' AND CUT_DATE = p_CUT_DATE;
      RETURN v_LOCAL_DAY;
   END FROM_CUT_TO_LOCAL_DAY;    
BEGIN
   IF p_PROCESS_ID IS NOT NULL THEN
-- Convert The Archive Begin And End Cut Dates To A Local Day Date Range For Standard Processing (Non-Repost) --      
      SELECT MIN(CUT_INTERVAL), MAX(CUT_INTERVAL) INTO v_BEGIN_DATE, v_END_DATE FROM CDI_MV90_ARCHIVE WHERE PROCESS_ID = p_PROCESS_ID;
      v_BEGIN_DATE := FROM_CUT_TO_LOCAL_DAY(v_BEGIN_DATE);
      v_END_DATE := FROM_CUT_TO_LOCAL_DAY(v_END_DATE);
   END IF;
   LOGS.LOG_INFO('Begin Date: ' || TO_CHAR(v_BEGIN_DATE, c_DATE_FORMAT) || ', End Date: ' || TO_CHAR(v_END_DATE, c_DATE_FORMAT));
-- Get The MV90 Content From The Archive For The Specified Time Period --   
   GET_MV90_COLLECTION(v_BEGIN_DATE, v_END_DATE, p_PROCESS_ID);
-- Stage The Accounts Represented In The MV90 Content -- 
   POST_MV90_IMPORT_CANDIDATES;
-- Stage Account Identity Of The Accounts Represented In The MV90 Content --
-- Post Errors Associated With The Content And The Data Model --
   POST_SERVICE_IDENTITY;
-- Iterate Over The Date Range And Store Service State And Service Load -- 
   v_SERVICE_DATE := v_BEGIN_DATE;
   WHILE v_SERVICE_DATE <= TRUNC(NVL(p_END_DATE, v_END_DATE)) LOOP
      LOGS.LOG_DEBUG('Post Service Load For: ' || TO_CHAR(v_SERVICE_DATE, c_DATE_FORMAT));
      DELETE_SERVICE(v_SERVICE_DATE, p_DELETE_ALL => CASE WHEN p_PROCESS_ID IS NULL THEN TRUE ELSE FALSE END);
      POST_SERVICE_STATE(v_SERVICE_DATE, v_SS_COUNT);
      POST_SERVICE_LOAD(v_SERVICE_DATE, v_SL_COUNT);
      POST_MV90_HOURLY_DEMAND(v_SERVICE_DATE, v_HD_COUNT);
      v_SERVICE_DATE := v_SERVICE_DATE + 1;
   END LOOP;
   LOGS.LOG_INFO('Service State Records Posted: ' || TO_CHAR(v_SS_COUNT));
   LOGS.LOG_INFO('Service Load Records Posted: ' || TO_CHAR(v_SL_COUNT));
   LOGS.LOG_INFO('Hourly Demand Records Posted: ' || TO_CHAR(v_HD_COUNT));
   LOGS.LOG_INFO('Process Interval Usage Complete. Elapsed Seconds: ' || TO_CHAR(ROUND((DBMS_UTILITY.GET_TIME-v_MARK_TIME)/100)));
END PROCESS_INTERVAL_USAGE;

PROCEDURE IMPORT_INTERVAL_USAGE(p_STATUS OUT NUMBER, p_MESSAGE OUT VARCHAR2) AS
v_PROCESS_ID NUMBER;
v_HAVE_CONTENT BOOLEAN;
v_MARK_TIME PLS_INTEGER := DBMS_UTILITY.GET_TIME;
BEGIN
   LOGS.START_PROCESS(c_IMPORT_INTERVAL_USAGE);
   LOGS.LOG_INFO(c_IMPORT_INTERVAL_USAGE);
   INITIALIZE_INTERFACE;
-- Step 1: Load Data From Temp_MV90_Usage_Archive CDI_MV90_DATA --
   POPULATE_STAGING_TABLE(v_HAVE_CONTENT, p_MESSAGE);
   IF v_HAVE_CONTENT THEN
-- Step 2: Archive Data From CDI_MV90_DATA Into CDI_MV90_ARCHIVE --
      ARCHIVE_MV90_DATA;
-- Step 3: Load Data From CDI_MV90_ARCHIVE For Billed Accounts --
      SELECT MAX(PROCESS_ID) INTO v_PROCESS_ID FROM CDI_MV90_DATA;
      IF v_PROCESS_ID IS NULL THEN
         p_MESSAGE := 'No New Content Posted To MV90 Archive Table To Process. See The Process Log For Details.';
         LOGS.LOG_INFO(p_MESSAGE);
      ELSE
         PROCESS_INTERVAL_USAGE(p_PROCESS_ID => v_PROCESS_ID);
         COMMIT;
         p_MESSAGE := c_IMPORT_INTERVAL_USAGE || ' Complete. See The Process Log For Details.';
         LOGS.LOG_INFO(c_IMPORT_INTERVAL_USAGE || ' Complete. Elapsed Seconds: ' || TO_CHAR(ROUND((DBMS_UTILITY.GET_TIME-v_MARK_TIME)/100)));
      END IF;
   END IF;
   LOGS.STOP_PROCESS(p_MESSAGE, p_STATUS);
EXCEPTION
   WHEN OTHERS THEN
      p_STATUS := SQLCODE;
      p_MESSAGE := SQLERRM;
      ERRS.ABORT_PROCESS;
END IMPORT_INTERVAL_USAGE;

PROCEDURE REPOST_INTERVAL_USAGE
   (
   p_BEGIN_DATE IN DATE,
   p_END_DATE   IN DATE,
   p_STATUS    OUT NUMBER,
   p_MESSAGE   OUT VARCHAR2
   ) AS
v_PROCESS_ID PLS_INTEGER;
v_MARK_TIME PLS_INTEGER := DBMS_UTILITY.GET_TIME;
BEGIN
   LOGS.START_PROCESS(c_REPOST_INTERVAL_USAGE);
   LOGS.LOG_INFO(c_REPOST_INTERVAL_USAGE);
   INITIALIZE_INTERFACE;
   SP.CHECK_SYSTEM_DATE_TIME(GA.LOCAL_TIME_ZONE, p_BEGIN_DATE, p_END_DATE);
   PROCESS_INTERVAL_USAGE(p_BEGIN_DATE, p_END_DATE);
   COMMIT;
   p_MESSAGE := c_REPOST_INTERVAL_USAGE || ' Complete. Elapsed Seconds: ' || TO_CHAR(ROUND((DBMS_UTILITY.GET_TIME-v_MARK_TIME)/100)) || '.';
   LOGS.LOG_INFO(p_MESSAGE);
   LOGS.STOP_PROCESS(p_MESSAGE, p_STATUS);
EXCEPTION
   WHEN OTHERS THEN
      P_STATUS := SQLCODE;
      p_MESSAGE := SQLERRM;
      ERRS.ABORT_PROCESS;
END REPOST_INTERVAL_USAGE;

PROCEDURE CACHE_LOSS_FACTOR(p_SERVICE_DATE IN DATE) AS
v_PROCEDURE VARCHAR2(32) := 'CACHE_LOSS_FACTOR';
CURSOR c_SELECT IS
   SELECT DISTINCT A.ACCOUNT_NAME, NVL(C.LOSS_FACTOR_NAME, c_DEFAULT_LOSS_FACTOR) "LOSS_FACTOR_NAME", NVL(E.EXPANSION_VAL,0) "EXPANSION_VAL"
   FROM ACCOUNT                    A
     LEFT JOIN ACCOUNT_LOSS_FACTOR B ON B.ACCOUNT_ID = A.ACCOUNT_ID AND p_SERVICE_DATE BETWEEN B.BEGIN_DATE AND NVL(B.END_DATE, CONSTANTS.HIGH_DATE)
     LEFT JOIN LOSS_FACTOR         C ON C.LOSS_FACTOR_ID = B.LOSS_FACTOR_ID
     LEFT JOIN LOSS_FACTOR_MODEL   D ON D.LOSS_FACTOR_ID = C.LOSS_FACTOR_ID AND D.LOSS_TYPE = CALC_UTIL.c_LOSS_TYPE_DISTRIBUTION AND p_SERVICE_DATE BETWEEN B.BEGIN_DATE AND NVL(B.END_DATE, CONSTANTS.HIGH_DATE)
     LEFT JOIN LOSS_FACTOR_PATTERN E ON E.PATTERN_ID = D.PATTERN_ID AND PATTERN_DATE = CONSTANTS.LOW_DATE
   WHERE ACCOUNT_NAME IN ('1234_1234_1234','3456_3456_3456','5678_5678_5678');
v_LOSS_FACTOR_ID NUMBER(9);
v_KEY VARCHAR2(32);
v_LOSS_FACTOR_NAME VARCHAR2(32) := NVL(GET_DICTIONARY_VALUE(c_SETTING_LOSS_FACTOR_NAME, GA.GLOBAL_MODEL, c_SYSTEM_SETTING_MODULE, c_SYSTEM_SETTING_KEY1, c_SYSTEM_SETTING_KEY2), c_DEFAULT_LOSS_FACTOR);
BEGIN
   l_LOSS_FACTOR_CACHE.DELETE;
   FOR v_SELECT IN c_SELECT LOOP
      SELECT NVL(MAX(LOSS_FACTOR_ID), CONSTANTS.NOT_ASSIGNED) INTO v_LOSS_FACTOR_ID FROM LOSS_FACTOR WHERE LOSS_FACTOR_NAME = v_LOSS_FACTOR_NAME;
      IF v_LOSS_FACTOR_ID = CONSTANTS.NOT_ASSIGNED THEN
         LOGS.LOG_WARN('No Loss Factor Defined For: ' || v_LOSS_FACTOR_NAME);
      END IF;
      v_KEY := v_SELECT.ACCOUNT_NAME;
      l_LOSS_FACTOR_CACHE(v_KEY) :=  v_SELECT.EXPANSION_VAL;
      LOGS.LOG_INFO('Loss Factor On ' || v_KEY || ': ' || TO_CHAR(l_LOSS_FACTOR_CACHE(v_KEY)));
   END LOOP;
END CACHE_LOSS_FACTOR;

FUNCTION GET_ACCOUNT_LOSS_FACTOR(p_ACCOUNT_NAME IN VARCHAR2) RETURN NUMBER AS
BEGIN
   RETURN CASE WHEN l_LOSS_FACTOR_CACHE.EXISTS(p_ACCOUNT_NAME) THEN l_LOSS_FACTOR_CACHE(p_ACCOUNT_NAME) ELSE 0 END;
END GET_ACCOUNT_LOSS_FACTOR;

PROCEDURE ALLOCATE_COMMUNITY_SOLAR(p_BEGIN_DATE IN DATE, p_END_DATE IN DATE) AS
/*
  Process Summary: The solar generation data is provided via both MV90 and AMI sourced information, and both sources need to be combined.
  Next, the solar generation should be aggregated by hour and then split across specific POLR types (R, PL1, PL2) based on configurable percentages.

  •   BGE customer information data and tables (Master Account) will continue to act as the source of data for creating required pseudo accounts in RO.
  •   AMI data is loaded to staging table – RTO_STAGING.COMM_SOLAR_GEN – by Service Agreement (customer)
  •   The Solar MV90 data will be provided by file, which is processed via the MV90 Data Exchange. Solar generators can be identified as having a Study ID of ‘SR%’. 
  •   A user will run a newly configured Data Exchange process to initiate aggregation and import of Community Solar Generation prior to running Settlement B.
      This process will calculate POLR type level generation values and import them into the applicable pseudo accounts.
    o   User will select the applicable Data Exchange name from the list of available entries
    o   Select appropriate dates for settlement B 
    o   Click “Run” and review system messages and process log
*/
v_STATUS NUMBER;
v_LOCAL_BEGIN_DATE DATE;
v_LOCAL_END_DATE   DATE;
v_CUT_BEGIN_DATE   DATE;
v_CUT_END_DATE     DATE;
v_MARK_TIME PLS_INTEGER := DBMS_UTILITY.GET_TIME;
v_MESSAGE          VARCHAR2(64);
BEGIN
   LOGS.START_PROCESS(c_ALLOCATE_COMMUNITY_SOLAR);
   LOGS.LOG_INFO(c_ALLOCATE_COMMUNITY_SOLAR);
   LOGS.LOG_INFO('Begin Date: ' || TO_CHAR(p_BEGIN_DATE, c_DATE_FORMAT) || ', End Date: ' || TO_CHAR(p_END_DATE, c_DATE_FORMAT));
-- Get Local Date Range --   
   UT.CUT_DATE_RANGE(p_BEGIN_DATE, p_END_DATE, GA.CUT_TIME_ZONE, v_LOCAL_BEGIN_DATE, v_LOCAL_END_DATE);
   LOGS.LOG_INFO('Local Begin Date-Time: ' || TO_CHAR(v_LOCAL_BEGIN_DATE, c_DATE_TIME_FORMAT) || ', Local End Date-Time: ' || TO_CHAR(v_LOCAL_END_DATE, c_DATE_TIME_FORMAT));
   UT.CUT_DATE_RANGE(p_BEGIN_DATE, p_END_DATE, GA.LOCAL_TIME_ZONE, v_CUT_BEGIN_DATE, v_CUT_END_DATE);
   LOGS.LOG_INFO('CUT Begin Date-Time: ' || TO_CHAR(v_CUT_BEGIN_DATE, c_DATE_TIME_FORMAT) || ', CUT End Date-Time: ' || TO_CHAR(v_CUT_END_DATE, c_DATE_TIME_FORMAT));
   CACHE_LOSS_FACTOR(p_BEGIN_DATE);
   DELETE SERVICE_LOAD
   WHERE SERVICE_CODE = CONSTANTS.CODE_ACTUAL
      AND LOAD_DATE BETWEEN v_CUT_BEGIN_DATE AND v_CUT_END_DATE
      AND SERVICE_ID IN
         (SELECT DISTINCT C.SERVICE_ID
         FROM ACCOUNT            A
            JOIN ACCOUNT_SERVICE B ON B.ACCOUNT_ID = A.ACCOUNT_ID
            JOIN SERVICE         C ON C.MODEL_ID = GA.ELECTRIC_MODEL AND C.SCENARIO_ID = GA.BASE_SCENARIO_ID AND C.AS_OF_DATE = CONSTANTS.LOW_DATE AND C.ACCOUNT_SERVICE_ID = B.ACCOUNT_SERVICE_ID
          WHERE A.ACCOUNT_NAME IN ('1234_1234_1234','3456_3456_3456','5678_5678_5678'));
   LOGS.LOG_INFO('Number Of Records Deleted From The SERVICE_LOAD Table: ' || TO_CHAR(SQL%ROWCOUNT));
   INSERT INTO SERVICE_LOAD(SERVICE_ID, SERVICE_CODE, LOAD_DATE, LOAD_CODE, LOAD_VAL, DX_LOSS_VAL)
   WITH
      SOLAR_GENERATION AS
         (SELECT LOAD_DATE, SUM(LOAD_VAL) "LOAD_VAL"
         FROM
            (SELECT 'MV90' "SOURCE", TRUNC(CUT_INTERVAL+59/1440,'HH') "LOAD_DATE", SUM(KW) "LOAD_VAL"
            FROM CDI_MV90_ARCHIVE
            WHERE CUT_INTERVAL BETWEEN v_LOCAL_BEGIN_DATE AND v_LOCAL_END_DATE
               AND CHANNEL LIKE 'SR%'
            GROUP BY TRUNC(CUT_INTERVAL+59/1440,'HH')
            UNION
            SELECT 'CSG', TRUNC(INTERVAL_START_DATE + CASE WHEN TO_CHAR(INTERVAL_START_DATE,'MI') <> '00' THEN 1/24 ELSE 0 END,'HH') "LOAD_DATE", SUM(VAL)*-1.0 "LOAD_VAL"
            FROM COMM_SOLAR_GEN
            WHERE INTERVAL_START_DATE BETWEEN v_LOCAL_BEGIN_DATE AND v_LOCAL_END_DATE
            GROUP BY TRUNC(INTERVAL_START_DATE + CASE WHEN TO_CHAR(INTERVAL_START_DATE,'MI') <> '00' THEN 1/24 ELSE 0 END,'HH'))
         GROUP BY LOAD_DATE),
      POLR_ACCOUNT_ALLOCATION AS
         (SELECT DISTINCT A.ACCOUNT_NAME, C.SERVICE_ID, ALLOCATION_PCT/100 "ALLOCATION_FACTOR"
         FROM ACCOUNT                           A
            JOIN ACCOUNT_SERVICE                B ON B.ACCOUNT_ID = A.ACCOUNT_ID
            JOIN SERVICE                        C ON C.MODEL_ID = GA.ELECTRIC_MODEL AND C.SCENARIO_ID = GA.BASE_SCENARIO_ID AND C.AS_OF_DATE = CONSTANTS.LOW_DATE AND C.ACCOUNT_SERVICE_ID = B.ACCOUNT_SERVICE_ID
            JOIN CDI_COMMUNITY_SOLAR_ALLOCATION D ON D.POLR_TYPE = CASE A.ACCOUNT_METER_EXT_IDENTIFIER WHEN 'SGRX' THEN 'R' WHEN 'SGP1' THEN 'PL1' WHEN 'SGP2' THEN 'PL2' ELSE '?' END AND p_BEGIN_DATE <= NVL(D.END_DATE, CONSTANTS.HIGH_DATE) AND p_END_DATE >= D.BEGIN_DATE
         WHERE A.ACCOUNT_NAME IN ('1234_1234_1234','3456_3456_3456','5678_5678_5678'))
   SELECT X.SERVICE_ID, CONSTANTS.CODE_ACTUAL, T.CUT_DATE, GA.STANDARD, X.LOAD_VAL, ROUND(X.LOAD_VAL * GET_ACCOUNT_LOSS_FACTOR(ACCOUNT_NAME), 3) "DX_LOSS_VAL"
   FROM (SELECT ACCOUNT_NAME, SERVICE_ID, LOAD_DATE, LOAD_VAL * ALLOCATION_FACTOR "LOAD_VAL" FROM SOLAR_GENERATION CROSS JOIN POLR_ACCOUNT_ALLOCATION) X
      JOIN CDI_EASTERN_PREVAILING_TIME$ T ON T.LOCAL_DATE = X.LOAD_DATE;
   LOGS.LOG_INFO('Number Of Records Posted To The SERVICE_LOAD Table: ' || TO_CHAR(SQL%ROWCOUNT));
   COMMIT;
   LOGS.LOG_INFO(c_ALLOCATE_COMMUNITY_SOLAR || ' Complete. Elapsed Seconds: ' || TO_CHAR(ROUND((DBMS_UTILITY.GET_TIME-v_MARK_TIME)/100)));
   LOGS.STOP_PROCESS(v_MESSAGE, v_STATUS);
EXCEPTION
   WHEN OTHERS THEN
      ERRS.ABORT_PROCESS;
END ALLOCATE_COMMUNITY_SOLAR;

END CDI_INTERVAL_USAGE;
/
